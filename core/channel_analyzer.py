"""
YouTube ì±„ë„ ë¶„ì„ ì „ìš© ëª¨ë“ˆ
ì±„ë„ ì •ë³´ ìˆ˜ì§‘, ì˜ìƒ ë¶„ì„, í†µê³„ ê³„ì‚° ë‹´ë‹¹
"""

import re
import urllib.parse
from datetime import datetime, timedelta
from googleapiclient.errors import HttpError

class ChannelAnalyzer:
    """YouTube ì±„ë„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, youtube_client):
        """
        ì±„ë„ ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            youtube_client: YouTubeClient ì¸ìŠ¤í„´ìŠ¤
        """
        self.client = youtube_client
    
    def analyze_channel(self, channel_id, video_count=50, sort_order="date"):
        """
        ì±„ë„ ì¢…í•© ë¶„ì„
        
        Args:
            channel_id (str): ì±„ë„ ID
            video_count (int): ë¶„ì„í•  ì˜ìƒ ìˆ˜
            sort_order (str): ì •ë ¬ ìˆœì„œ ("date", "viewCount")
            
        Returns:
            dict: ì±„ë„ ë¶„ì„ ê²°ê³¼
        """
        print(f"ğŸ“º ì±„ë„ ë¶„ì„ ì‹œì‘: {channel_id}")
        
        try:
            # 1. ì±„ë„ ê¸°ë³¸ ì •ë³´
            channel_info = self.client.get_channel_info(channel_id)
            if not channel_info:
                return {'error': 'ì±„ë„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
            
            # 2. ì±„ë„ ì˜ìƒ ëª©ë¡
            videos = self.get_channel_videos(channel_id, video_count, sort_order)
            if not videos:
                return {'error': 'ì±„ë„ ì˜ìƒì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
            
            # 3. ì±„ë„ í†µê³„ ê³„ì‚°
            channel_stats = self.calculate_channel_statistics(videos)
            
            # 4. ì„±ê³¼ ë¶„ì„
            performance_analysis = self.analyze_video_performance(videos)
            
            # 5. íŠ¸ë Œë“œ ë¶„ì„
            trend_analysis = self.analyze_upload_trends(videos)
            
            # 6. ì»¨í…ì¸  ë¶„ì„
            content_analysis = self.analyze_content_patterns(videos)
            
            return {
                'channel_info': channel_info,
                'videos': videos,
                'statistics': channel_stats,
                'performance': performance_analysis,
                'trends': trend_analysis,
                'content': content_analysis,
                'analyzed_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"âŒ ì±„ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def get_channel_videos(self, channel_id, max_results=50, order='date'):
        """
        ì±„ë„ì˜ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            channel_id (str): ì±„ë„ ID
            max_results (int): ìµœëŒ€ ì˜ìƒ ìˆ˜
            order (str): ì •ë ¬ ìˆœì„œ
            
        Returns:
            list: ì˜ìƒ ëª©ë¡
        """
        try:
            print(f"ğŸ“¹ ì±„ë„ ì˜ìƒ ìˆ˜ì§‘: {max_results}ê°œ")
            
            # 1. ì±„ë„ì˜ ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ê°€ì ¸ì˜¤ê¸°
            channel_request = self.client.youtube.channels().list(
                part='contentDetails',
                id=channel_id
            )
            channel_response = channel_request.execute()
            
            if not channel_response['items']:
                print(f"âŒ ì±„ë„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {channel_id}")
                return []
            
            uploads_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
            self.client.quota_used += 1
            
            # 2. í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì—ì„œ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            playlist_items = self.client.get_playlist_items(uploads_playlist_id, max_results)
            
            if not playlist_items:
                return []
            
            # 3. ì˜ìƒ ID ì¶”ì¶œ
            video_ids = [item['snippet']['resourceId']['videoId'] for item in playlist_items]
            
            # 4. ì˜ìƒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            videos = self.client.get_video_details(video_ids)
            
            # 5. ì •ë ¬
            if order == 'viewCount':
                videos.sort(key=lambda x: int(x['statistics'].get('viewCount', 0)), reverse=True)
            elif order == 'date':
                videos.sort(key=lambda x: x['snippet']['publishedAt'], reverse=True)
            
            print(f"âœ… ì±„ë„ ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ: {len(videos)}ê°œ")
            return videos
            
        except Exception as e:
            print(f"âŒ ì±„ë„ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
            return []
    
    def calculate_channel_statistics(self, videos):
        """
        ì±„ë„ í†µê³„ ê³„ì‚°
        
        Args:
            videos (list): ì˜ìƒ ëª©ë¡
            
        Returns:
            dict: ì±„ë„ í†µê³„
        """
        if not videos:
            return {}
        
        try:
            # ê¸°ë³¸ í†µê³„
            total_videos = len(videos)
            total_views = sum(int(v['statistics'].get('viewCount', 0)) for v in videos)
            total_likes = sum(int(v['statistics'].get('likeCount', 0)) for v in videos)
            total_comments = sum(int(v['statistics'].get('commentCount', 0)) for v in videos)
            
            # í‰ê·  í†µê³„
            avg_views = total_views / total_videos if total_videos > 0 else 0
            avg_likes = total_likes / total_videos if total_videos > 0 else 0
            avg_comments = total_comments / total_videos if total_videos > 0 else 0
            
            # ìµœê³ /ìµœì € ì„±ê³¼
            view_counts = [int(v['statistics'].get('viewCount', 0)) for v in videos]
            max_views = max(view_counts) if view_counts else 0
            min_views = min(view_counts) if view_counts else 0
            
            # ì°¸ì—¬ë„ ê³„ì‚°
            engagement_rates = []
            for video in videos:
                views = int(video['statistics'].get('viewCount', 0))
                likes = int(video['statistics'].get('likeCount', 0))
                comments = int(video['statistics'].get('commentCount', 0))
                
                if views > 0:
                    engagement_rate = ((likes + comments) / views) * 100
                    engagement_rates.append(engagement_rate)
            
            avg_engagement = sum(engagement_rates) / len(engagement_rates) if engagement_rates else 0
            
            # ì˜ìƒ ìœ í˜•ë³„ í†µê³„
            shorts_count = 0
            long_count = 0
            
            for video in videos:
                try:
                    duration_str = video['contentDetails']['duration']
                    duration_seconds = self.client.parse_duration(duration_str)
                    
                    if duration_seconds <= 60:
                        shorts_count += 1
                    else:
                        long_count += 1
                except:
                    continue
            
            return {
                'total_videos': total_videos,
                'total_views': total_views,
                'total_likes': total_likes,
                'total_comments': total_comments,
                'avg_views': round(avg_views, 2),
                'avg_likes': round(avg_likes, 2),
                'avg_comments': round(avg_comments, 2),
                'max_views': max_views,
                'min_views': min_views,
                'avg_engagement_rate': round(avg_engagement, 4),
                'shorts_count': shorts_count,
                'long_videos_count': long_count,
                'shorts_ratio': round((shorts_count / total_videos * 100), 2) if total_videos > 0 else 0
            }
            
        except Exception as e:
            print(f"âŒ ì±„ë„ í†µê³„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {}
    
    def analyze_video_performance(self, videos):
        """
        ì˜ìƒ ì„±ê³¼ ë¶„ì„
        
        Args:
            videos (list): ì˜ìƒ ëª©ë¡
            
        Returns:
            dict: ì„±ê³¼ ë¶„ì„ ê²°ê³¼
        """
        if not videos:
            return {}
        
        try:
            # ì¡°íšŒìˆ˜ ê¸°ì¤€ ì„±ê³¼ ë¶„ì„
            view_counts = [int(v['statistics'].get('viewCount', 0)) for v in videos]
            avg_views = sum(view_counts) / len(view_counts)
            
            # ì„±ê³¼ë³„ ì˜ìƒ ë¶„ë¥˜
            viral_videos = []  # í‰ê· ì˜ 5ë°° ì´ìƒ
            hit_videos = []    # í‰ê· ì˜ 3ë°° ì´ìƒ
            good_videos = []   # í‰ê· ì˜ 1.5ë°° ì´ìƒ
            poor_videos = []   # í‰ê· ì˜ 0.7ë°° ë¯¸ë§Œ
            
            for video in videos:
                views = int(video['statistics'].get('viewCount', 0))
                ratio = views / avg_views if avg_views > 0 else 0
                
                video_performance = {
                    'video': video,
                    'views': views,
                    'performance_ratio': ratio
                }
                
                if ratio >= 5.0:
                    viral_videos.append(video_performance)
                elif ratio >= 3.0:
                    hit_videos.append(video_performance)
                elif ratio >= 1.5:
                    good_videos.append(video_performance)
                elif ratio < 0.7:
                    poor_videos.append(video_performance)
            
            # ìµœê³  ì„±ê³¼ ì˜ìƒë“¤
            top_videos = sorted(videos, key=lambda x: int(x['statistics'].get('viewCount', 0)), reverse=True)[:5]
            
            return {
                'avg_views': avg_views,
                'viral_count': len(viral_videos),
                'hit_count': len(hit_videos),
                'good_count': len(good_videos),
                'poor_count': len(poor_videos),
                'viral_videos': viral_videos[:3],  # ìƒìœ„ 3ê°œë§Œ
                'hit_videos': hit_videos[:3],
                'top_videos': top_videos,
                'performance_distribution': {
                    'viral': round(len(viral_videos) / len(videos) * 100, 2),
                    'hit': round(len(hit_videos) / len(videos) * 100, 2),
                    'good': round(len(good_videos) / len(videos) * 100, 2),
                    'poor': round(len(poor_videos) / len(videos) * 100, 2)
                }
            }
            
        except Exception as e:
            print(f"âŒ ì„±ê³¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {}
    
    def analyze_upload_trends(self, videos):
        """
        ì—…ë¡œë“œ íŠ¸ë Œë“œ ë¶„ì„
        
        Args:
            videos (list): ì˜ìƒ ëª©ë¡
            
        Returns:
            dict: íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼
        """
        if not videos:
            return {}
        
        try:
            # ì›”ë³„ ì—…ë¡œë“œ íŒ¨í„´
            monthly_uploads = {}
            daily_uploads = {'Monday': 0, 'Tuesday': 0, 'Wednesday': 0, 'Thursday': 0, 
                           'Friday': 0, 'Saturday': 0, 'Sunday': 0}
            
            for video in videos:
                try:
                    published_at = video['snippet']['publishedAt']
                    dt = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
                    
                    # ì›”ë³„
                    month_key = dt.strftime('%Y-%m')
                    monthly_uploads[month_key] = monthly_uploads.get(month_key, 0) + 1
                    
                    # ìš”ì¼ë³„
                    day_name = dt.strftime('%A')
                    daily_uploads[day_name] += 1
                    
                except:
                    continue
            
            # ìµœê·¼ í™œë™ íŒ¨í„´
            recent_30days = [v for v in videos if self._is_recent_video(v, 30)]
            recent_7days = [v for v in videos if self._is_recent_video(v, 7)]
            
            # ì—…ë¡œë“œ ì£¼ê¸° ê³„ì‚°
            upload_frequency = self._calculate_upload_frequency(videos)
            
            return {
                'monthly_uploads': monthly_uploads,
                'daily_pattern': daily_uploads,
                'most_active_day': max(daily_uploads, key=daily_uploads.get),
                'recent_30days_count': len(recent_30days),
                'recent_7days_count': len(recent_7days),
                'upload_frequency_days': upload_frequency,
                'consistency_score': self._calculate_consistency_score(monthly_uploads)
            }
            
        except Exception as e:
            print(f"âŒ ì—…ë¡œë“œ íŠ¸ë Œë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {}
    
    def analyze_content_patterns(self, videos):
        """
        ì»¨í…ì¸  íŒ¨í„´ ë¶„ì„
        
        Args:
            videos (list): ì˜ìƒ ëª©ë¡
            
        Returns:
            dict: ì»¨í…ì¸  ë¶„ì„ ê²°ê³¼
        """
        if not videos:
            return {}
        
        try:
            # ì œëª© ê¸¸ì´ ë¶„ì„
            title_lengths = [len(v['snippet']['title']) for v in videos]
            avg_title_length = sum(title_lengths) / len(title_lengths)
            
            # ì˜ìƒ ê¸¸ì´ ë¶„ì„
            durations = []
            for video in videos:
                try:
                    duration_str = video['contentDetails']['duration']
                    duration_seconds = self.client.parse_duration(duration_str)
                    durations.append(duration_seconds)
                except:
                    continue
            
            avg_duration = sum(durations) / len(durations) if durations else 0
            
            # ì„±ê³¼ ì¢‹ì€ ì˜ìƒë“¤ì˜ íŒ¨í„´
            top_performers = sorted(videos, key=lambda x: int(x['statistics'].get('viewCount', 0)), reverse=True)[:10]
            
            top_title_lengths = [len(v['snippet']['title']) for v in top_performers]
            avg_top_title_length = sum(top_title_lengths) / len(top_title_lengths) if top_title_lengths else 0
            
            # ì¹´í…Œê³ ë¦¬ ë¶„ì„
            categories = {}
            for video in videos:
                category_id = video['snippet'].get('categoryId', 'Unknown')
                categories[category_id] = categories.get(category_id, 0) + 1
            
            most_used_category = max(categories, key=categories.get) if categories else 'Unknown'
            
            return {
                'avg_title_length': round(avg_title_length, 2),
                'avg_duration_seconds': round(avg_duration, 2),
                'avg_duration_formatted': self._format_duration(avg_duration),
                'top_performers_avg_title_length': round(avg_top_title_length, 2),
                'category_distribution': categories,
                'most_used_category': most_used_category,
                'title_length_range': {
                    'min': min(title_lengths) if title_lengths else 0,
                    'max': max(title_lengths) if title_lengths else 0
                },
                'duration_range': {
                    'min_seconds': min(durations) if durations else 0,
                    'max_seconds': max(durations) if durations else 0,
                    'min_formatted': self._format_duration(min(durations)) if durations else "00:00",
                    'max_formatted': self._format_duration(max(durations)) if durations else "00:00"
                }
            }
            
        except Exception as e:
            print(f"âŒ ì»¨í…ì¸  íŒ¨í„´ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {}
    
    def extract_channel_id_from_url(self, url_or_id):
        """
        URL ë˜ëŠ” í•¸ë“¤ì—ì„œ ì±„ë„ ID ì¶”ì¶œ
        
        Args:
            url_or_id (str): ì±„ë„ URL, í•¸ë“¤, ë˜ëŠ” ID
            
        Returns:
            tuple: (channel_id, channel_name)
        """
        try:
            url_or_id = url_or_id.strip()
            
            # ì´ë¯¸ ì±„ë„ IDì¸ ê²½ìš°
            if url_or_id.startswith('UC') and len(url_or_id) == 24:
                return url_or_id, None
            
            # URLì—ì„œ ì¶”ì¶œ
            patterns = [
                (r'youtube\.com/channel/([a-zA-Z0-9_-]+)', 'channel'),
                (r'youtube\.com/c/([^/?]+)', 'custom'),
                (r'youtube\.com/user/([^/?]+)', 'user'),
                (r'youtube\.com/@([^/?]+)', 'handle'),
                (r'youtube\.com/([a-zA-Z0-9ê°€-í£_-]+)$', 'legacy')
            ]
            
            for pattern, url_type in patterns:
                match = re.search(pattern, url_or_id)
                if match:
                    identifier = match.group(1)
                    identifier = urllib.parse.unquote(identifier, encoding='utf-8')
                    
                    if identifier.startswith('UC') and len(identifier) == 24:
                        return identifier, None
                    
                    # APIë¡œ ì±„ë„ ID ì°¾ê¸°
                    channel_id = self._resolve_channel_identifier(identifier, url_type)
                    if channel_id:
                        return channel_id, identifier
            
            # ì§ì ‘ ê²€ìƒ‰
            channel_id = self._search_channel_by_name(url_or_id)
            if channel_id:
                return channel_id, url_or_id
            
            return None, None
            
        except Exception as e:
            print(f"ì±„ë„ ID ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None, None
    
    def _resolve_channel_identifier(self, identifier, url_type):
        """ì±„ë„ ì‹ë³„ìë¥¼ ì±„ë„ IDë¡œ ë³€í™˜"""
        try:
            channels = self.client.search_channels(identifier, max_results=10)
            
            for channel in channels:
                channel_title = channel['snippet']['title']
                custom_url = channel['snippet'].get('customUrl', '')
                
                # ì •í™•í•œ ë§¤ì¹˜ í™•ì¸
                if (custom_url.lower() == f"@{identifier.lower()}" or
                    custom_url.lower() == identifier.lower() or
                    channel_title.lower() == identifier.lower()):
                    return channel['snippet']['channelId']
            
            # ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
            if channels:
                return channels[0]['snippet']['channelId']
            
            return None
            
        except Exception as e:
            print(f"ì±„ë„ ì‹ë³„ì í•´ê²° ì˜¤ë¥˜: {e}")
            return None
    
    def _search_channel_by_name(self, channel_name):
        """ì±„ë„ëª…ìœ¼ë¡œ ê²€ìƒ‰"""
        try:
            channels = self.client.search_channels(channel_name, max_results=5)
            
            for channel in channels:
                found_title = channel['snippet']['title']
                if self._is_channel_name_match(channel_name, found_title):
                    return channel['snippet']['channelId']
            
            # ì²« ë²ˆì§¸ ê²°ê³¼ ë°˜í™˜
            if channels:
                return channels[0]['snippet']['channelId']
            
            return None
            
        except Exception as e:
            print(f"ì±„ë„ëª… ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return None
    
    def _is_channel_name_match(self, input_name, found_name):
        """ì±„ë„ëª… ë§¤ì¹˜ í™•ì¸"""
        input_normalized = input_name.lower().strip().replace(' ', '')
        found_normalized = found_name.lower().strip().replace(' ', '')
        
        return (input_normalized == found_normalized or
                input_normalized in found_normalized or
                found_normalized in input_normalized)
    
    def _is_recent_video(self, video, days):
        """ìµœê·¼ ì˜ìƒì¸ì§€ í™•ì¸"""
        try:
            published_at = video['snippet']['publishedAt']
            dt = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
            cutoff_date = datetime.now(dt.tzinfo) - timedelta(days=days)
            return dt >= cutoff_date
        except:
            return False
    
    def _calculate_upload_frequency(self, videos):
        """ì—…ë¡œë“œ ì£¼ê¸° ê³„ì‚° (ì¼ ë‹¨ìœ„)"""
        if len(videos) < 2:
            return 0
        
        try:
            dates = []
            for video in videos:
                published_at = video['snippet']['publishedAt']
                dt = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
                dates.append(dt)
            
            dates.sort()
            
            # ì—°ì†ëœ ì—…ë¡œë“œ ê°„ì˜ ê°„ê²© ê³„ì‚°
            intervals = []
            for i in range(1, len(dates)):
                interval = (dates[i] - dates[i-1]).days
                intervals.append(interval)
            
            return sum(intervals) / len(intervals) if intervals else 0
            
        except:
            return 0
    
    def _calculate_consistency_score(self, monthly_uploads):
        """ì—…ë¡œë“œ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        if not monthly_uploads:
            return 0
        
        try:
            upload_counts = list(monthly_uploads.values())
            if len(upload_counts) < 2:
                return 100
            
            # í‘œì¤€í¸ì°¨ ê¸°ë°˜ ì¼ê´€ì„± ì ìˆ˜
            mean_uploads = sum(upload_counts) / len(upload_counts)
            variance = sum((x - mean_uploads) ** 2 for x in upload_counts) / len(upload_counts)
            std_dev = variance ** 0.5
            
            # ë³€ë™ê³„ìˆ˜ì˜ ì—­ìˆ˜ë¡œ ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°
            cv = std_dev / mean_uploads if mean_uploads > 0 else float('inf')
            consistency_score = max(0, 100 - (cv * 50))
            
            return round(consistency_score, 2)
            
        except:
            return 0
    
    def _format_duration(self, seconds):
        """ì´ˆë¥¼ ì‹œ:ë¶„:ì´ˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        
        if hours > 0:
            return f"{hours}:{minutes:02d}:{secs:02d}"
        else:
            return f"{minutes:02d}:{secs:02d}"