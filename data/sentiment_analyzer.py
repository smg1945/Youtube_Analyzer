"""
ê°ì • ë¶„ì„ ì „ìš© ëª¨ë“ˆ
ëŒ“ê¸€ ê°ì • ë¶„ì„, ê¸ì •/ë¶€ì • ë¶„ë¥˜, ê°ì • íŠ¸ë Œë“œ ë¶„ì„ ë‹´ë‹¹
"""

import re
from collections import Counter, defaultdict

# ì„ íƒì  import
try:
    from textblob import TextBlob
    TEXTBLOB_AVAILABLE = True
except ImportError:
    TEXTBLOB_AVAILABLE = False
    print("âš ï¸ TextBlobì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê³ ê¸‰ ê°ì • ë¶„ì„ì´ ì œí•œë©ë‹ˆë‹¤.")

try:
    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
    VADER_AVAILABLE = True
except ImportError:
    VADER_AVAILABLE = False
    print("âš ï¸ VADER Sentimentê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì†Œì…œë¯¸ë””ì–´ ê°ì • ë¶„ì„ì´ ì œí•œë©ë‹ˆë‹¤.")

class SentimentAnalyzer:
    """ê°ì • ë¶„ì„ í´ëž˜ìŠ¤"""
    
    def __init__(self, language="ko"):
        """
        ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            language (str): ë¶„ì„ ì–¸ì–´ ("ko" ë˜ëŠ” "en")
        """
        self.language = language
        
        # VADER ë¶„ì„ê¸° ì´ˆê¸°í™” (ì˜ì–´, ì†Œì…œë¯¸ë””ì–´ íŠ¹í™”)
        if VADER_AVAILABLE:
            self.vader_analyzer = SentimentIntensityAnalyzer()
        else:
            self.vader_analyzer = None
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ì‚¬ì „ ë¡œë“œ
        self.sentiment_keywords = self._load_sentiment_keywords(language)
        
        print(f"âœ… ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ì–¸ì–´: {language})")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ì§„: {self._get_available_engines()}")
    
    def analyze_comments_sentiment(self, comments):
        """
        ëŒ“ê¸€ ê°ì • ë¶„ì„
        
        Args:
            comments (list): ëŒ“ê¸€ ëª©ë¡ [{'text': 'ëŒ“ê¸€ë‚´ìš©', ...}, ...]
            
        Returns:
            dict: ê°ì • ë¶„ì„ ê²°ê³¼
        """
        if not comments:
            return {
                'positive': 0.0,
                'neutral': 0.0,
                'negative': 0.0,
                'total_comments': 0,
                'analysis_method': 'none'
            }
        
        print(f"ðŸ’­ ëŒ“ê¸€ ê°ì • ë¶„ì„ ì‹œìž‘: {len(comments)}ê°œ")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì ì˜ ë¶„ì„ ë°©ë²• ì„ íƒ
        if TEXTBLOB_AVAILABLE and self.language == "en":
            result = self._analyze_with_textblob(comments)
            result['analysis_method'] = 'textblob'
        elif VADER_AVAILABLE:
            result = self._analyze_with_vader(comments)
            result['analysis_method'] = 'vader'
        else:
            result = self._analyze_with_keywords(comments)
            result['analysis_method'] = 'keywords'
        
        result['total_comments'] = len(comments)
        
        print(f"âœ… ê°ì • ë¶„ì„ ì™„ë£Œ: ê¸ì • {result['positive']:.1f}%, "
              f"ì¤‘ë¦½ {result['neutral']:.1f}%, ë¶€ì • {result['negative']:.1f}%")
        
        return result
    
    def _analyze_with_textblob(self, comments):
        """TextBlobì„ ì‚¬ìš©í•œ ê°ì • ë¶„ì„"""
        positive_count = 0
        negative_count = 0
        neutral_count = 0
        sentiment_scores = []
        
        for comment in comments:
            try:
                text = comment.get('text', '') if isinstance(comment, dict) else str(comment)
                blob = TextBlob(text)
                polarity = blob.sentiment.polarity
                sentiment_scores.append(polarity)
                
                if polarity > 0.1:
                    positive_count += 1
                elif polarity < -0.1:
                    negative_count += 1
                else:
                    neutral_count += 1
                    
            except Exception as e:
                neutral_count += 1  # ë¶„ì„ ì‹¤íŒ¨ì‹œ ì¤‘ë¦½ìœ¼ë¡œ ì²˜ë¦¬
        
        total = len(comments)
        if total == 0:
            return {'positive': 0.0, 'neutral': 0.0, 'negative': 0.0}
        
        return {
            'positive': round(positive_count / total * 100, 2),
            'neutral': round(neutral_count / total * 100, 2),
            'negative': round(negative_count / total * 100, 2),
            'avg_sentiment_score': round(sum(sentiment_scores) / len(sentiment_scores), 3) if sentiment_scores else 0,
            'sentiment_distribution': {
                'scores': sentiment_scores,
                'std_dev': self._calculate_std_dev(sentiment_scores)
            }
        }
    
    def _analyze_with_vader(self, comments):
        """VADERë¥¼ ì‚¬ìš©í•œ ê°ì • ë¶„ì„ (ì†Œì…œë¯¸ë””ì–´ íŠ¹í™”)"""
        positive_count = 0
        negative_count = 0
        neutral_count = 0
        compound_scores = []
        
        for comment in comments:
            try:
                text = comment.get('text', '') if isinstance(comment, dict) else str(comment)
                scores = self.vader_analyzer.polarity_scores(text)
                compound = scores['compound']
                compound_scores.append(compound)
                
                # VADERì˜ compound score ê¸°ì¤€
                if compound >= 0.05:
                    positive_count += 1
                elif compound <= -0.05:
                    negative_count += 1
                else:
                    neutral_count += 1
                    
            except Exception as e:
                neutral_count += 1
        
        total = len(comments)
        if total == 0:
            return {'positive': 0.0, 'neutral': 0.0, 'negative': 0.0}
        
        return {
            'positive': round(positive_count / total * 100, 2),
            'neutral': round(neutral_count / total * 100, 2),
            'negative': round(negative_count / total * 100, 2),
            'avg_compound_score': round(sum(compound_scores) / len(compound_scores), 3) if compound_scores else 0,
            'sentiment_intensity': self._categorize_sentiment_intensity(compound_scores)
        }
    
    def _analyze_with_keywords(self, comments):
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„"""
        positive_count = 0
        negative_count = 0
        keyword_matches = {'positive': [], 'negative': []}
        
        pos_keywords = self.sentiment_keywords['positive']
        neg_keywords = self.sentiment_keywords['negative']
        
        for comment in comments:
            try:
                text = comment.get('text', '') if isinstance(comment, dict) else str(comment)
                text_lower = text.lower()
                
                # ê¸ì • í‚¤ì›Œë“œ ë§¤ì¹­
                pos_matches = [word for word in pos_keywords if word in text_lower]
                neg_matches = [word for word in neg_keywords if word in text_lower]
                
                if pos_matches and not neg_matches:
                    positive_count += 1
                    keyword_matches['positive'].extend(pos_matches)
                elif neg_matches and not pos_matches:
                    negative_count += 1
                    keyword_matches['negative'].extend(neg_matches)
                elif pos_matches and neg_matches:
                    # ë‘˜ ë‹¤ ìžˆìœ¼ë©´ ë” ë§Žì€ ìª½ìœ¼ë¡œ ë¶„ë¥˜
                    if len(pos_matches) > len(neg_matches):
                        positive_count += 1
                        keyword_matches['positive'].extend(pos_matches)
                    else:
                        negative_count += 1
                        keyword_matches['negative'].extend(neg_matches)
                # ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ ì¤‘ë¦½
                
            except Exception as e:
                continue
        
        total = len(comments)
        neutral_count = total - positive_count - negative_count
        
        if total == 0:
            return {'positive': 0.0, 'neutral': 0.0, 'negative': 0.0}
        
        return {
            'positive': round(positive_count / total * 100, 2),
            'neutral': round(neutral_count / total * 100, 2),
            'negative': round(negative_count / total * 100, 2),
            'keyword_analysis': {
                'positive_keywords_found': Counter(keyword_matches['positive']),
                'negative_keywords_found': Counter(keyword_matches['negative']),
                'total_positive_matches': len(keyword_matches['positive']),
                'total_negative_matches': len(keyword_matches['negative'])
            }
        }
    
    def analyze_sentiment_trends(self, time_series_comments):
        """
        ì‹œê°„ë³„ ê°ì • íŠ¸ë Œë“œ ë¶„ì„
        
        Args:
            time_series_comments (list): [{'date': '2024-01-01', 'comments': [...]}, ...]
            
        Returns:
            dict: ì‹œê°„ë³„ ê°ì • íŠ¸ë Œë“œ
        """
        trends = {}
        
        for data_point in time_series_comments:
            date = data_point['date']
            comments = data_point['comments']
            
            sentiment_result = self.analyze_comments_sentiment(comments)
            trends[date] = sentiment_result
        
        # íŠ¸ë Œë“œ ìš”ì•½
        summary = self._summarize_sentiment_trends(trends)
        
        return {
            'daily_trends': trends,
            'trend_summary': summary,
            'analysis_period': {
                'start_date': min(trends.keys()) if trends else None,
                'end_date': max(trends.keys()) if trends else None,
                'total_days': len(trends)
            }
        }
    
    def detect_sentiment_anomalies(self, comments, threshold=2.0):
        """
        ê°ì • ì´ìƒì¹˜ íƒì§€
        
        Args:
            comments (list): ëŒ“ê¸€ ëª©ë¡
            threshold (float): ì´ìƒì¹˜ ê¸°ì¤€ (í‘œì¤€íŽ¸ì°¨ ë°°ìˆ˜)
            
        Returns:
            dict: ì´ìƒì¹˜ íƒì§€ ê²°ê³¼
        """
        if not comments:
            return {'anomalies': [], 'total_anomalies': 0}
        
        # ê°œë³„ ëŒ“ê¸€ì˜ ê°ì • ì ìˆ˜ ê³„ì‚°
        comment_sentiments = []
        
        for i, comment in enumerate(comments):
            text = comment.get('text', '') if isinstance(comment, dict) else str(comment)
            
            # ë‹¨ì¼ ëŒ“ê¸€ ê°ì • ë¶„ì„
            single_result = self.analyze_comments_sentiment([comment])
            
            # ê°ì • ì ìˆ˜ ê³„ì‚° (ê¸ì •: +1, ì¤‘ë¦½: 0, ë¶€ì •: -1ì˜ ê°€ì¤‘ í‰ê· )
            sentiment_score = (single_result['positive'] - single_result['negative']) / 100
            
            comment_sentiments.append({
                'index': i,
                'text': text[:100] + '...' if len(text) > 100 else text,
                'sentiment_score': sentiment_score,
                'classification': self._classify_single_sentiment(single_result)
            })
        
        # í‰ê· ê³¼ í‘œì¤€íŽ¸ì°¨ ê³„ì‚°
        scores = [cs['sentiment_score'] for cs in comment_sentiments]
        mean_score = sum(scores) / len(scores)
        std_dev = self._calculate_std_dev(scores)
        
        # ì´ìƒì¹˜ íƒì§€
        anomalies = []
        for cs in comment_sentiments:
            deviation = abs(cs['sentiment_score'] - mean_score)
            if deviation > threshold * std_dev:
                cs['anomaly_score'] = deviation / std_dev
                anomalies.append(cs)
        
        # ì´ìƒì¹˜ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        anomalies.sort(key=lambda x: x['anomaly_score'], reverse=True)
        
        return {
            'anomalies': anomalies,
            'total_anomalies': len(anomalies),
            'anomaly_rate': round(len(anomalies) / len(comments) * 100, 2),
            'sentiment_stats': {
                'mean_score': round(mean_score, 3),
                'std_dev': round(std_dev, 3),
                'threshold_used': threshold
            }
        }
    
    def analyze_emotional_keywords(self, comments):
        """
        ê°ì •ë³„ í‚¤ì›Œë“œ ë¶„ì„
        
        Args:
            comments (list): ëŒ“ê¸€ ëª©ë¡
            
        Returns:
            dict: ê°ì •ë³„ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼
        """
        emotional_keywords = {
            'positive': defaultdict(int),
            'negative': defaultdict(int),
            'neutral': defaultdict(int)
        }
        
        for comment in comments:
            text = comment.get('text', '') if isinstance(comment, dict) else str(comment)
            
            # ë‹¨ì¼ ëŒ“ê¸€ ê°ì • ë¶„ì„
            sentiment = self.analyze_comments_sentiment([comment])
            
            # ê°ì • ë¶„ë¥˜
            if sentiment['positive'] > max(sentiment['negative'], sentiment['neutral']):
                category = 'positive'
            elif sentiment['negative'] > max(sentiment['positive'], sentiment['neutral']):
                category = 'negative'
            else:
                category = 'neutral'
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
            words = re.findall(r'\b\w+\b', text.lower())
            for word in words:
                if len(word) > 2:  # 3ê¸€ìž ì´ìƒ
                    emotional_keywords[category][word] += 1
        
        # ê° ê°ì •ë³„ ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
        result = {}
        for emotion, keywords in emotional_keywords.items():
            top_keywords = dict(Counter(keywords).most_common(20))
            result[emotion] = {
                'keywords': top_keywords,
                'total_words': sum(keywords.values()),
                'unique_words': len(keywords)
            }
        
        return result
    
    def _load_sentiment_keywords(self, language):
        """ì–¸ì–´ë³„ ê°ì • í‚¤ì›Œë“œ ì‚¬ì „ ë¡œë“œ"""
        keywords = {
            'ko': {
                'positive': [
                    'ì¢‹ë‹¤', 'ìµœê³ ', 'ëŒ€ë°•', 'ë©‹ì§€ë‹¤', 'í›Œë¥­', 'ì™„ë²½', 'ì‚¬ëž‘', 'ê°ì‚¬', 
                    'ìž¬ë°Œ', 'ì›ƒê²¨', 'êµ¿', 'ë² ìŠ¤íŠ¸', 'ì¢‹ì•„', 'ì˜ˆì˜ë‹¤', 'ë§›ìžˆ', 'í–‰ë³µ',
                    'ê¸°ì˜ë‹¤', 'ë†€ëž', 'ì‹ ê¸°', 'ëŒ€ë‹¨', 'ì©ë‹¤', 'ê°œì¢‹', 'ê°œì›ƒ', 'í‚¹ë°›',
                    'ê·¹ì°¬', 'ì¶”ì²œ', 'ì¸ì •', 'ë ˆì „ë“œ', 'ê°“', 'í˜œìž', 'ê¿€', 'ì§±'
                ],
                'negative': [
                    'ì‹«ë‹¤', 'ë³„ë¡œ', 'ìµœì•…', 'ë‚˜ì˜ë‹¤', 'ì§œì¦', 'í™”ë‚˜', 'ì‹¤ë§', 'ì•ˆì¢‹', 
                    'ëª»í•´', 'ì–´ì´ì—†', 'ë¹¡ì¹˜', 'ìž¬ë¯¸ì—†', 'ì§€ê²¨', 'ë‹µë‹µ', 'í›„íšŒ',
                    'ë”ì°', 'ì—­ê²¨', 'ëª»ìƒ', 'ì¶”í•˜', 'ë”ëŸ½', 'ê°œë¹¡', 'ì—´ë°›', 'ë¹ŒëŸ°',
                    'ì“°ë ˆê¸°', 'ë§í•¨', 'ì‹¤íŒ¨', 'ì—‰ë§', 'ê°œë³„ë¡œ', 'ë…¸ìž¼', 'í•µë…¸ìž¼'
                ]
            },
            'en': {
                'positive': [
                    'good', 'great', 'amazing', 'awesome', 'perfect', 'love', 'best', 
                    'wonderful', 'excellent', 'fantastic', 'brilliant', 'outstanding',
                    'incredible', 'beautiful', 'nice', 'cool', 'sweet', 'fun',
                    'happy', 'joy', 'pleased', 'satisfied', 'impressed', 'wow'
                ],
                'negative': [
                    'bad', 'terrible', 'awful', 'hate', 'worst', 'disappointing', 
                    'boring', 'stupid', 'horrible', 'disgusting', 'annoying',
                    'frustrating', 'pathetic', 'useless', 'waste', 'crap',
                    'sucks', 'lame', 'dumb', 'ridiculous', 'trash', 'garbage'
                ]
            }
        }
        
        return keywords.get(language, keywords['en'])
    
    def _classify_single_sentiment(self, sentiment_result):
        """ë‹¨ì¼ ê°ì • ê²°ê³¼ ë¶„ë¥˜"""
        positive = sentiment_result['positive']
        negative = sentiment_result['negative']
        neutral = sentiment_result['neutral']
        
        if positive > max(negative, neutral):
            return 'positive'
        elif negative > max(positive, neutral):
            return 'negative'
        else:
            return 'neutral'
    
    def _categorize_sentiment_intensity(self, compound_scores):
        """ê°ì • ê°•ë„ ì¹´í…Œê³ ë¦¬í™”"""
        if not compound_scores:
            return {}
        
        intensities = {
            'very_positive': len([s for s in compound_scores if s >= 0.5]),
            'positive': len([s for s in compound_scores if 0.05 <= s < 0.5]),
            'neutral': len([s for s in compound_scores if -0.05 < s < 0.05]),
            'negative': len([s for s in compound_scores if -0.5 < s <= -0.05]),
            'very_negative': len([s for s in compound_scores if s <= -0.5])
        }
        
        total = len(compound_scores)
        return {
            category: {
                'count': count,
                'percentage': round(count / total * 100, 2)
            }
            for category, count in intensities.items()
        }
    
    def _summarize_sentiment_trends(self, trends):
        """ê°ì • íŠ¸ë Œë“œ ìš”ì•½"""
        if not trends:
            return {}
        
        dates = sorted(trends.keys())
        
        # ê° ê°ì •ì˜ ì‹œê°„ë³„ ë³€í™”
        positive_trend = [trends[date]['positive'] for date in dates]
        negative_trend = [trends[date]['negative'] for date in dates]
        neutral_trend = [trends[date]['neutral'] for date in dates]
        
        return {
            'overall_trend': {
                'positive': {
                    'avg': round(sum(positive_trend) / len(positive_trend), 2),
                    'trend': self._calculate_trend_direction(positive_trend)
                },
                'negative': {
                    'avg': round(sum(negative_trend) / len(negative_trend), 2),
                    'trend': self._calculate_trend_direction(negative_trend)
                },
                'neutral': {
                    'avg': round(sum(neutral_trend) / len(neutral_trend), 2),
                    'trend': self._calculate_trend_direction(neutral_trend)
                }
            },
            'volatility': {
                'positive': round(self._calculate_std_dev(positive_trend), 2),
                'negative': round(self._calculate_std_dev(negative_trend), 2),
                'neutral': round(self._calculate_std_dev(neutral_trend), 2)
            }
        }
    
    def _calculate_trend_direction(self, values):
        """íŠ¸ë Œë“œ ë°©í–¥ ê³„ì‚°"""
        if len(values) < 2:
            return 'stable'
        
        # ì„ í˜• íŠ¸ë Œë“œ ê³„ì‚° (ê°„ë‹¨í•œ ë°©ë²•)
        first_half = sum(values[:len(values)//2]) / (len(values)//2)
        second_half = sum(values[len(values)//2:]) / (len(values) - len(values)//2)
        
        diff = second_half - first_half
        
        if diff > 2:
            return 'rising'
        elif diff < -2:
            return 'falling'
        else:
            return 'stable'
    
    def _calculate_std_dev(self, values):
        """í‘œì¤€íŽ¸ì°¨ ê³„ì‚°"""
        if not values:
            return 0
        
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        return variance ** 0.5
    
    def _get_available_engines(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ê°ì • ë¶„ì„ ì—”ì§„ ëª©ë¡"""
        engines = ['keywords']  # ê¸°ë³¸ í‚¤ì›Œë“œ ë°©ì‹ì€ í•­ìƒ ì‚¬ìš© ê°€ëŠ¥
        
        if TEXTBLOB_AVAILABLE:
            engines.append('textblob')
        if VADER_AVAILABLE:
            engines.append('vader')
        
        return engines
    
    def get_analysis_info(self):
        """ë¶„ì„ ì •ë³´ ë°˜í™˜"""
        return {
            'language': self.language,
            'available_engines': self._get_available_engines(),
            'textblob_available': TEXTBLOB_AVAILABLE,
            'vader_available': VADER_AVAILABLE,
            'features': {
                'basic_sentiment': True,
                'sentiment_trends': True,
                'anomaly_detection': True,
                'emotional_keywords': True,
                'intensity_analysis': VADER_AVAILABLE,
                'multilingual': TEXTBLOB_AVAILABLE
            },
            'keyword_dictionary_size': {
                'positive': len(self.sentiment_keywords['positive']),
                'negative': len(self.sentiment_keywords['negative'])
            }
        }


# ê°ì • ë¶„ì„ ê²°ê³¼ í›„ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
class SentimentResultProcessor:
    """ê°ì • ë¶„ì„ ê²°ê³¼ í›„ì²˜ë¦¬ í´ëž˜ìŠ¤"""
    
    @staticmethod
    def normalize_sentiment_scores(sentiment_results):
        """ê°ì • ì ìˆ˜ ì •ê·œí™”"""
        total = sentiment_results['positive'] + sentiment_results['negative'] + sentiment_results['neutral']
        
        if total == 0:
            return sentiment_results
        
        return {
            'positive': round(sentiment_results['positive'] / total * 100, 2),
            'negative': round(sentiment_results['negative'] / total * 100, 2),
            'neutral': round(sentiment_results['neutral'] / total * 100, 2)
        }
    
    @staticmethod
    def get_dominant_sentiment(sentiment_results):
        """ì£¼ìš” ê°ì • ì¶”ì¶œ"""
        sentiments = ['positive', 'negative', 'neutral']
        max_sentiment = max(sentiments, key=lambda s: sentiment_results.get(s, 0))
        
        return {
            'dominant_sentiment': max_sentiment,
            'confidence': sentiment_results.get(max_sentiment, 0),
            'sentiment_distribution': sentiment_results
        }
    
    @staticmethod
    def calculate_sentiment_polarity(sentiment_results):
        """ê°ì • ê·¹ì„± ê³„ì‚° (-1 ~ +1)"""
        positive = sentiment_results.get('positive', 0)
        negative = sentiment_results.get('negative', 0)
        
        total_polar = positive + negative
        if total_polar == 0:
            return 0.0
        
        polarity = (positive - negative) / total_polar
        return round(polarity, 3)