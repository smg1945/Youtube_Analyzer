"""
YouTube Data API ê´€ë ¨ í•¨ìˆ˜ë“¤
"""

import os
import re
import requests
import time
from datetime import datetime, timedelta
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from PIL import Image
from io import BytesIO
import config

class YouTubeAPIClient:
    def __init__(self, api_key=None):
        """YouTube API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.api_key = api_key or config.DEVELOPER_KEY
        self.youtube = build(
            config.YOUTUBE_API_SERVICE_NAME,
            config.YOUTUBE_API_VERSION,
            developerKey=self.api_key
        )
        self.quota_used = 0
        self.quota_limit = config.API_QUOTA_LIMIT
        
    def check_quota_remaining(self):
        """ë‚¨ì€ í• ë‹¹ëŸ‰ í™•ì¸"""
        remaining = self.quota_limit - self.quota_used
        return max(0, remaining)
    
    def can_use_quota(self, required_units):
        """í•„ìš”í•œ í• ë‹¹ëŸ‰ì„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸"""
        return self.quota_used + required_units <= self.quota_limit
    
    def get_quota_status(self):
        """í• ë‹¹ëŸ‰ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        used_percentage = (self.quota_used / self.quota_limit) * 100
        return {
            'used': self.quota_used,
            'limit': self.quota_limit,
            'remaining': self.check_quota_remaining(),
            'percentage': used_percentage,
            'status': 'high' if used_percentage > 80 else 'medium' if used_percentage > 50 else 'low'
        }

    def get_trending_videos(self, region_code="KR", category_id=None, max_results=200):
        """
        ì‹¤ì‹œê°„ íŠ¸ë Œë”© ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ë” ë§ì€ ì˜ìƒì„ ìˆ˜ì§‘í•´ì„œ outlier ë¶„ì„)
        
        Args:
            region_code (str): ì§€ì—­ ì½”ë“œ (KR, US ë“±)
            category_id (str): ì¹´í…Œê³ ë¦¬ ID (Noneì´ë©´ ì „ì²´)
            max_results (int): ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            list: íŠ¸ë Œë”© ì˜ìƒ ëª©ë¡
        """
        try:
            # API í• ë‹¹ëŸ‰ í™•ì¸
            if not self.can_use_quota(1):
                raise Exception("API í• ë‹¹ëŸ‰ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            
            request_params = {
                'part': 'snippet,statistics,contentDetails',
                'chart': 'mostPopular',
                'regionCode': region_code,
                'maxResults': max_results
            }
            
            if category_id and category_id != "all":
                request_params['videoCategoryId'] = category_id
            
            request = self.youtube.videos().list(**request_params)
            response = request.execute()
            
            self.quota_used += 1  # API í• ë‹¹ëŸ‰ ì¶”ì 
            
            return response.get('items', [])
            
        except HttpError as e:
            if "quotaExceeded" in str(e):
                raise Exception("YouTube API ì¼ì¼ í• ë‹¹ëŸ‰ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                print(f"YouTube API ì˜¤ë¥˜: {e}")
                return []

    def get_trending_shorts(self, region_code="KR", max_results=200):
        """
        íŠ¸ë Œë”© ì‡¼ì¸  ì˜ìƒ ê°€ì ¸ì˜¤ê¸° (ê²€ìƒ‰ ê¸°ë°˜)
        
        Args:
            region_code (str): ì§€ì—­ ì½”ë“œ
            max_results (int): ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            list: ì‡¼ì¸  ì˜ìƒ ëª©ë¡
        """
        try:
            from datetime import datetime, timedelta
            
            # ìµœê·¼ 7ì¼ê°„ì˜ ì˜ìƒ ì¤‘ì—ì„œ ê²€ìƒ‰
            published_after = (datetime.now() - timedelta(days=7)).isoformat() + 'Z'
            
            all_shorts = []
            
            # ë°©ë²• 1: ì‡¼ì¸  ê´€ë ¨ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
            search_queries = ['#Shorts', 'Shorts', 'ì‡¼ì¸ '] if region_code == 'KR' else ['#Shorts', 'Shorts']
            
            for query in search_queries:
                try:
                    search_request = self.youtube.search().list(
                        part='snippet',
                        q=query,
                        type='video',
                        order='viewCount',
                        publishedAfter=published_after,
                        regionCode=region_code,
                        maxResults=30,
                        relevanceLanguage='ko' if region_code == 'KR' else 'en'
                    )
                    search_response = search_request.execute()
                    
                    self.quota_used += 100  # search API ì‚¬ìš©ëŸ‰
                    
                    # ì˜ìƒ ID ì¶”ì¶œ
                    video_ids = [item['id']['videoId'] for item in search_response.get('items', [])]
                    
                    if video_ids:
                        # ì˜ìƒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        videos_details = self.get_video_details(video_ids)
                        
                        # ì‹¤ì œë¡œ ì‡¼ì¸ ì¸ì§€ í™•ì¸ (60ì´ˆ ì´í•˜)
                        for video in videos_details:
                            duration = self.parse_duration(video['contentDetails']['duration'])
                            if duration <= 60:  # 60ì´ˆ ì´í•˜ë§Œ ì‡¼ì¸ ë¡œ ì¸ì •
                                all_shorts.append(video)
                    
                except Exception as e:
                    print(f"ì‡¼ì¸  ê²€ìƒ‰ ì˜¤ë¥˜ (ì¿¼ë¦¬: {query}): {e}")
                    continue
            
            # ë°©ë²• 2: ì¼ë°˜ ê²€ìƒ‰ì—ì„œ ì§§ì€ ì˜ìƒë“¤ ì°¾ê¸°
            try:
                # ì¸ê¸° ìˆëŠ” ì¹´í…Œê³ ë¦¬ì—ì„œ ìµœê·¼ ì˜ìƒ ê²€ìƒ‰
                popular_categories = ['10', '20', '22', '23', '24']  # ìŒì•…, ê²Œì„, ë¸”ë¡œê·¸, ì½”ë¯¸ë””, ì—”í„°í…Œì¸ë¨¼íŠ¸
                
                for category in popular_categories:
                    search_request = self.youtube.search().list(
                        part='snippet',
                        type='video',
                        order='viewCount',
                        publishedAfter=published_after,
                        regionCode=region_code,
                        maxResults=20,
                        relevanceLanguage='ko' if region_code == 'KR' else 'en'
                    )
                    search_response = search_request.execute()
                    
                    self.quota_used += 100
                    
                    video_ids = [item['id']['videoId'] for item in search_response.get('items', [])]
                    
                    if video_ids:
                        videos_details = self.get_video_details(video_ids)
                        
                        for video in videos_details:
                            duration = self.parse_duration(video['contentDetails']['duration'])
                            if duration <= 60:
                                all_shorts.append(video)
                                
            except Exception as e:
                print(f"ì¹´í…Œê³ ë¦¬ë³„ ì‡¼ì¸  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            
            # ì¤‘ë³µ ì œê±° (video ID ê¸°ì¤€)
            seen_ids = set()
            unique_shorts = []
            for video in all_shorts:
                if video['id'] not in seen_ids:
                    seen_ids.add(video['id'])
                    unique_shorts.append(video)
            
            # ì¡°íšŒìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            unique_shorts.sort(key=lambda x: int(x.get('statistics', {}).get('viewCount', 0)), reverse=True)
            
            print(f"ğŸ¬ ì´ {len(unique_shorts)}ê°œì˜ ì‡¼ì¸ ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
            
            return unique_shorts[:max_results]
            
        except Exception as e:
            print(f"ì‡¼ì¸  ê²€ìƒ‰ ì „ì²´ ì˜¤ë¥˜: {e}")
            return []

    def search_videos_by_keyword(self, keyword, region_code="KR", max_results=200, 
                                max_subscriber_count=None, min_view_count=None, period_days=30):
        """
        í‚¤ì›Œë“œë¡œ ì˜ìƒ ê²€ìƒ‰ (êµ¬ë…ì ìˆ˜, ì¡°íšŒìˆ˜ í•„í„° í¬í•¨)
        
        Args:
            keyword (str): ê²€ìƒ‰ í‚¤ì›Œë“œ
            region_code (str): ì§€ì—­ ì½”ë“œ
            max_results (int): ìµœëŒ€ ê²°ê³¼ ìˆ˜
            max_subscriber_count (int): ìµœëŒ€ êµ¬ë…ì ìˆ˜ (Noneì´ë©´ ì œí•œ ì—†ìŒ)
            min_view_count (int): ìµœì†Œ ì¡°íšŒìˆ˜ (Noneì´ë©´ ì œí•œ ì—†ìŒ)
            period_days (int): ê²€ìƒ‰ ê¸°ê°„ (ì¼)
            
        Returns:
            list: ê²€ìƒ‰ëœ ì˜ìƒ ëª©ë¡
        """
        try:
            from datetime import datetime, timedelta
            
            # ê²€ìƒ‰ ê¸°ê°„ ì„¤ì •
            published_after = (datetime.now() - timedelta(days=period_days)).isoformat() + 'Z'
            
            print(f"ğŸ” '{keyword}' í‚¤ì›Œë“œë¡œ ìµœê·¼ {period_days}ì¼ ì˜ìƒ ê²€ìƒ‰ ì¤‘...")
            
            # í‚¤ì›Œë“œë¡œ ì˜ìƒ ê²€ìƒ‰
            search_request = self.youtube.search().list(
                part='snippet',
                q=keyword,
                type='video',
                order='date',  # ìµœì‹ ìˆœ ì •ë ¬
                publishedAfter=published_after,
                regionCode=region_code,
                maxResults=max_results,
                relevanceLanguage='ko' if region_code == 'KR' else 'en'
            )
            search_response = search_request.execute()
            
            self.quota_used += 100  # search API ì‚¬ìš©ëŸ‰
            
            # ì˜ìƒ ID ì¶”ì¶œ
            video_ids = [item['id']['videoId'] for item in search_response.get('items', [])]
            
            if not video_ids:
                return []
            
            # ì˜ìƒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            videos_details = self.get_video_details(video_ids)
            
            print(f"ğŸ“Š {len(videos_details)}ê°œ ì˜ìƒ ë°œê²¬, í•„í„°ë§ ì ìš© ì¤‘...")
            
            # ì±„ë„ë³„ êµ¬ë…ì ìˆ˜ ìºì‹œ
            channel_subscriber_cache = {}
            filtered_videos = []
            
            for video in videos_details:
                try:
                    channel_id = video['snippet']['channelId']
                    video_views = int(video['statistics'].get('viewCount', 0))
                    
                    # ì¡°íšŒìˆ˜ í•„í„° ì²´í¬
                    if min_view_count and video_views < min_view_count:
                        continue
                    
                    # êµ¬ë…ì ìˆ˜ í•„í„° ì²´í¬ (í•„ìš”í•œ ê²½ìš°ë§Œ)
                    if max_subscriber_count:
                        if channel_id not in channel_subscriber_cache:
                            channel_info = self.get_channel_info(channel_id)
                            if channel_info:
                                subscriber_count = int(channel_info['statistics'].get('subscriberCount', 0))
                                channel_subscriber_cache[channel_id] = subscriber_count
                            else:
                                channel_subscriber_cache[channel_id] = 0
                        
                        channel_subscribers = channel_subscriber_cache[channel_id]
                        if channel_subscribers > max_subscriber_count:
                            continue
                    
                    # í•„í„° í†µê³¼í•œ ì˜ìƒ ì¶”ê°€
                    filtered_videos.append(video)
                    
                except Exception as e:
                    print(f"ì˜ìƒ í•„í„°ë§ ì˜¤ë¥˜ (ID: {video.get('id', 'Unknown')}): {e}")
                    continue
            
            # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬ (í•œ ë²ˆ ë” í™•ì‹¤í•˜ê²Œ)
            filtered_videos.sort(key=lambda x: x['snippet']['publishedAt'], reverse=True)
            
            print(f"âœ… í•„í„°ë§ ì™„ë£Œ: {len(filtered_videos)}ê°œ ì˜ìƒ")
            
            return filtered_videos
            
        except Exception as e:
            print(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def get_video_details(self, video_ids):
        """
        ì˜ìƒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            video_ids (list): ì˜ìƒ ID ëª©ë¡
            
        Returns:
            list: ì˜ìƒ ìƒì„¸ ì •ë³´ ëª©ë¡
        """
        try:
            # APIëŠ” í•œ ë²ˆì— ìµœëŒ€ 50ê°œ ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
            video_details = []
            
            for i in range(0, len(video_ids), 50):
                batch_ids = video_ids[i:i+50]
                
                request = self.youtube.videos().list(
                    part='snippet,statistics,contentDetails,status',
                    id=','.join(batch_ids)
                )
                response = request.execute()
                video_details.extend(response.get('items', []))
                
                self.quota_used += 1
                time.sleep(0.1)  # API ìš”ì²­ ì œí•œ ê³ ë ¤
            
            return video_details
            
        except HttpError as e:
            print(f"ì˜ìƒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
            return []

    def get_video_comments(self, video_id, max_results=50):
        """
        ì˜ìƒ ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            video_id (str): ì˜ìƒ ID
            max_results (int): ìµœëŒ€ ëŒ“ê¸€ ìˆ˜
            
        Returns:
            list: ëŒ“ê¸€ ëª©ë¡
        """
        try:
            request = self.youtube.commentThreads().list(
                part='snippet',
                videoId=video_id,
                maxResults=max_results,
                order='relevance'  # ê´€ë ¨ì„± ìˆœìœ¼ë¡œ ì •ë ¬
            )
            response = request.execute()
            
            self.quota_used += 1
            
            comments = []
            for item in response.get('items', []):
                comment = item['snippet']['topLevelComment']['snippet']
                comments.append({
                    'text': comment['textDisplay'],
                    'author': comment['authorDisplayName'],
                    'likes': comment['likeCount'],
                    'published_at': comment['publishedAt']
                })
            
            return comments
            
        except HttpError as e:
            print(f"ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜ (ì˜ìƒ ID: {video_id}): {e}")
            return []

    def download_thumbnail(self, thumbnail_url, video_id, video_title="", rank=0, quality="high"):
        """ì¸ë„¤ì¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
        if not thumbnail_url:
            return None
            
        try:
            response = requests.get(thumbnail_url, timeout=10)
            if response.status_code == 200:
                os.makedirs('thumbnails', exist_ok=True)
                
                safe_title = re.sub(r'[^\w\s-]', '', video_title.replace(' ', '_'))[:30]
                if rank > 0:
                    filename = f"{rank:03d}_{safe_title}_{video_id}.jpg"
                else:
                    filename = f"{safe_title}_{video_id}.jpg"
                
                image_path = f'thumbnails/{filename}'
                
                with open(image_path, 'wb') as f:
                    f.write(response.content)
                
                print(f"âœ… ì¸ë„¤ì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename}")
                return image_path
            else:
                print(f"âŒ ì¸ë„¤ì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (HTTP {response.status_code}): {thumbnail_url}")
                return None
        except Exception as e:
            print(f"âŒ ì¸ë„¤ì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None

    def download_multiple_thumbnails(self, videos_info):
        """
        ì—¬ëŸ¬ ì˜ìƒì˜ ì¸ë„¤ì¼ì„ ì¼ê´„ ë‹¤ìš´ë¡œë“œ
        
        Args:
            videos_info (list): [{'video_id': str, 'title': str, 'thumbnail_url': str, 'rank': int}]
            
        Returns:
            dict: ë‹¤ìš´ë¡œë“œ ê²°ê³¼
        """
        try:
            print(f"ğŸ–¼ï¸ {len(videos_info)}ê°œ ì˜ìƒì˜ ì¸ë„¤ì¼ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            downloaded_files = []
            failed_count = 0
            
            for i, video_info in enumerate(videos_info, 1):
                print(f"   ì§„í–‰ë¥ : {i}/{len(videos_info)} - {video_info.get('title', '')[:30]}...", end="\r")
                
                result = self.download_thumbnail(
                    video_info['thumbnail_url'],
                    video_info['video_id'],
                    video_info.get('title', ''),
                    video_info.get('rank', 0)
                )
                
                if result:
                    downloaded_files.append(result)
                else:
                    failed_count += 1
            
            print(f"\nâœ… ì¸ë„¤ì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            print(f"   ì„±ê³µ: {len(downloaded_files)}ê°œ")
            print(f"   ì‹¤íŒ¨: {failed_count}ê°œ")
            
            # ZIP íŒŒì¼ ìƒì„±
            if downloaded_files:
                zip_filename = self.create_thumbnails_zip(downloaded_files)
                return {
                    'success': True,
                    'downloaded_files': downloaded_files,
                    'failed_count': failed_count,
                    'zip_file': zip_filename
                }
            else:
                return {
                    'success': False,
                    'error': 'ë‹¤ìš´ë¡œë“œëœ ì¸ë„¤ì¼ì´ ì—†ìŠµë‹ˆë‹¤'
                }
                
        except Exception as e:
            print(f"âŒ ì¸ë„¤ì¼ ì¼ê´„ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': str(e)}

    def create_thumbnails_zip(self, thumbnail_files):
        """ì¸ë„¤ì¼ íŒŒì¼ë“¤ì„ ZIPìœ¼ë¡œ ì••ì¶•"""
        try:
            from datetime import datetime
            import zipfile
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            zip_filename = f"selected_thumbnails_{timestamp}.zip"
            
            with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file_path in thumbnail_files:
                    if os.path.exists(file_path):
                        filename = os.path.basename(file_path)
                        zipf.write(file_path, filename)
            
            print(f"ğŸ“¦ ì¸ë„¤ì¼ ZIP íŒŒì¼ ìƒì„±: {zip_filename}")
            return zip_filename
            
        except Exception as e:
            print(f"âŒ ì¸ë„¤ì¼ ZIP ìƒì„± ì˜¤ë¥˜: {e}")
            return None

    def get_channel_videos(self, channel_id, max_results=50, order='date'):
        """
        ì±„ë„ì˜ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            channel_id (str): ì±„ë„ ID
            max_results (int): ìµœëŒ€ ê²°ê³¼ ìˆ˜
            order (str): ì •ë ¬ ë°©ì‹ ('date', 'viewCount', 'relevance')
            
        Returns:
            list: ì±„ë„ ì˜ìƒ ëª©ë¡
        """
        try:
            # ì±„ë„ì˜ ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ê°€ì ¸ì˜¤ê¸°
            channel_request = self.youtube.channels().list(
                part='contentDetails',
                id=channel_id
            )
            channel_response = channel_request.execute()
            
            if not channel_response['items']:
                return []
            
            # ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID
            uploads_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
            
            self.quota_used += 1
            
            # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì—ì„œ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            videos = []
            next_page_token = None
            
            while len(videos) < max_results:
                playlist_request = self.youtube.playlistItems().list(
                    part='snippet',
                    playlistId=uploads_playlist_id,
                    maxResults=min(50, max_results - len(videos)),
                    pageToken=next_page_token
                )
                playlist_response = playlist_request.execute()
                
                self.quota_used += 1
                
                for item in playlist_response['items']:
                    video_info = {
                        'id': item['snippet']['resourceId']['videoId'],
                        'title': item['snippet']['title'],
                        'description': item['snippet']['description'][:200] + '...' if len(item['snippet']['description']) > 200 else item['snippet']['description'],
                        'published_at': item['snippet']['publishedAt'],
                        'thumbnail_url': item['snippet']['thumbnails'].get('medium', {}).get('url', '')
                    }
                    videos.append(video_info)
                
                next_page_token = playlist_response.get('nextPageToken')
                if not next_page_token:
                    break
            
            # ì˜ìƒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì¡°íšŒìˆ˜, ì¢‹ì•„ìš” ë“±)
            if videos:
                video_ids = [video['id'] for video in videos]
                detailed_videos = self.get_video_details(video_ids)
                
                # ìƒì„¸ ì •ë³´ì™€ ê¸°ë³¸ ì •ë³´ í•©ì¹˜ê¸°
                detailed_video_dict = {video['id']: video for video in detailed_videos}
                
                for video in videos:
                    if video['id'] in detailed_video_dict:
                        detailed_info = detailed_video_dict[video['id']]
                        video.update({
                            'view_count': int(detailed_info['statistics'].get('viewCount', 0)),
                            'like_count': int(detailed_info['statistics'].get('likeCount', 0)),
                            'comment_count': int(detailed_info['statistics'].get('commentCount', 0)),
                            'duration': detailed_info['contentDetails']['duration']
                        })
            
            # ì •ë ¬
            if order == 'viewCount':
                videos.sort(key=lambda x: x.get('view_count', 0), reverse=True)
            elif order == 'date':
                videos.sort(key=lambda x: x['published_at'], reverse=True)
            
            return videos[:max_results]
            
        except Exception as e:
            print(f"ì±„ë„ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
            return []
            
            response = requests.get(thumbnail_url, timeout=10)
            if response.status_code == 200:
                # ì¸ë„¤ì¼ í´ë” ìƒì„±
                os.makedirs('thumbnails', exist_ok=True)
                
                # íŒŒì¼ëª… ìƒì„± (ìˆœìœ„_ì œëª©_ì˜ìƒID.jpg)
                # ì œëª©ì—ì„œ íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
                safe_title = re.sub(r'[^\w\s-]', '', video_title.replace(' ', '_'))[:30]
                if rank > 0:
                    filename = f"{rank:03d}_{safe_title}_{video_id}.jpg"
                else:
                    filename = f"{safe_title}_{video_id}.jpg"
                
                image_path = f'thumbnails/{filename}'
                
                # ì´ë¯¸ì§€ ì €ì¥
                with open(image_path, 'wb') as f:
                    f.write(response.content)
                
                return image_path
            else:
                print(f"ì¸ë„¤ì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (HTTP {response.status_code}): {thumbnail_url}")
                return None
                
        except Exception as e:
            print(f"ì¸ë„¤ì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None

    def get_best_thumbnail_url(self, thumbnails):
        """
        ìµœê³  í’ˆì§ˆì˜ ì¸ë„¤ì¼ URL ë°˜í™˜
        
        Args:
            thumbnails (dict): YouTube APIì˜ thumbnails ë”•ì…”ë„ˆë¦¬
            
        Returns:
            str: ìµœê³  í’ˆì§ˆ ì¸ë„¤ì¼ URL
        """
        # í’ˆì§ˆ ìš°ì„ ìˆœìœ„: maxres > high > medium > default
        quality_priority = ['maxres', 'high', 'medium', 'default']
        
        for quality in quality_priority:
            if quality in thumbnails:
                return thumbnails[quality]['url']
        
        return None

    def parse_duration(self, duration_str):
        """
        YouTube APIì˜ duration ë¬¸ìì—´ì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
        
        Args:
            duration_str (str): PT15M33S í˜•íƒœì˜ duration ë¬¸ìì—´
            
        Returns:
            int: ì´ˆ ë‹¨ìœ„ duration
        """
        import re
        
        # PT15M33S í˜•íƒœì—ì„œ ì‹œê°„, ë¶„, ì´ˆ ì¶”ì¶œ
        pattern = r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?'
        match = re.match(pattern, duration_str)
        
        if not match:
            return 0
        
        hours = int(match.group(1) or 0)
        minutes = int(match.group(2) or 0)
        seconds = int(match.group(3) or 0)
        
        return hours * 3600 + minutes * 60 + seconds

    def filter_videos_by_type(self, videos, video_type="all"):
        """
        ì˜ìƒ ìœ í˜•ë³„ í•„í„°ë§ (ì „ì²´/ë¡±í¼/ì‡¼ì¸ )
        
        Args:
            videos (list): ì˜ìƒ ëª©ë¡
            video_type (str): "all", "long", "shorts"
            
        Returns:
            list: í•„í„°ë§ëœ ì˜ìƒ ëª©ë¡
        """
        if video_type == "all":
            return videos
        
        filtered_videos = []
        
        for video in videos:
            duration = self.parse_duration(video['contentDetails']['duration'])
            
            if video_type == "shorts" and duration <= config.SHORT_VIDEO_MAX_DURATION:
                filtered_videos.append(video)
            elif video_type == "long" and duration > config.LONG_VIDEO_MIN_DURATION:
                filtered_videos.append(video)
        
        return filtered_videos

    def get_channel_info(self, channel_id):
        """
        ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            channel_id (str): ì±„ë„ ID
            
        Returns:
            dict: ì±„ë„ ì •ë³´
        """
        try:
            request = self.youtube.channels().list(
                part='snippet,statistics',
                id=channel_id
            )
            response = request.execute()
            
            self.quota_used += 1
            
            if response['items']:
                return response['items'][0]
            else:
                return None
                
        except HttpError as e:
            print(f"ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
            return None

    def get_channel_recent_videos_stats(self, channel_id, max_results=10):
        """
        ì±„ë„ì˜ ìµœê·¼ ì˜ìƒë“¤ í†µê³„ ê°€ì ¸ì˜¤ê¸° (outlier score ê³„ì‚°ìš©)
        
        Args:
            channel_id (str): ì±„ë„ ID
            max_results (int): ë¶„ì„í•  ìµœê·¼ ì˜ìƒ ìˆ˜
            
        Returns:
            dict: í‰ê·  ì¡°íšŒìˆ˜, ì¢‹ì•„ìš”, ëŒ“ê¸€ ìˆ˜ ë“±
        """
        try:
            # ì±„ë„ì˜ ìµœê·¼ ì˜ìƒ ê²€ìƒ‰
            search_request = self.youtube.search().list(
                part='snippet',
                channelId=channel_id,
                type='video',
                order='date',
                maxResults=max_results
            )
            search_response = search_request.execute()
            
            self.quota_used += 100  # search API ì‚¬ìš©ëŸ‰
            
            # ì˜ìƒ ID ì¶”ì¶œ
            video_ids = [item['id']['videoId'] for item in search_response.get('items', [])]
            
            if not video_ids:
                return None
            
            # ì˜ìƒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            videos_stats = self.get_video_details(video_ids)
            
            # í†µê³„ ê³„ì‚°
            view_counts = []
            like_counts = []
            comment_counts = []
            
            for video in videos_stats:
                stats = video.get('statistics', {})
                view_counts.append(int(stats.get('viewCount', 0)))
                like_counts.append(int(stats.get('likeCount', 0)))
                comment_counts.append(int(stats.get('commentCount', 0)))
            
            if not view_counts:
                return None
            
            # í‰ê·  ê³„ì‚°
            avg_stats = {
                'avg_views': sum(view_counts) / len(view_counts),
                'avg_likes': sum(like_counts) / len(like_counts),
                'avg_comments': sum(comment_counts) / len(comment_counts),
                'video_count': len(view_counts),
                'max_views': max(view_counts),
                'min_views': min(view_counts)
            }
            
            return avg_stats
            
        except HttpError as e:
            print(f"ì±„ë„ í†µê³„ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜ (ì±„ë„ ID: {channel_id}): {e}")
            return None

    def get_quota_usage(self):
        """í˜„ì¬ API í• ë‹¹ëŸ‰ ì‚¬ìš©ëŸ‰ ë°˜í™˜"""
        return self.quota_used